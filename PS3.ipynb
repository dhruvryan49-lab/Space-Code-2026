{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SPACECODE_PS3_BEETLEJUICE2.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score, precision_score, f1_score, roc_curve\n",
                "from imblearn.over_sampling import SMOTE\n",
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from collections import Counter\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "import time\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette(\"husl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(r'd:\\as\\nasa_neows_1950_2025.csv', low_memory=False)\n",
                "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "columns_to_drop = ['Neo Reference ID', 'Name', 'Date', 'Close Approach Date', 'Orbit Determination Date', 'Equinox', 'Orbiting Body']\n",
                "cols_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
                "df = df.drop(columns=cols_to_drop)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
                "for col in numeric_cols:\n",
                "    if df[col].isnull().sum() > 0:\n",
                "        df[col] = df[col].fillna(df[col].median())\n",
                "\n",
                "df = df.dropna(subset=['Hazardous'])\n",
                "df['Hazardous'] = df['Hazardous'].map({'True': True, 'False': False, True: True, False: False})\n",
                "df['Hazardous'] = df['Hazardous'].astype(int)\n",
                "\n",
                "print(f\"Safe: {(df['Hazardous'] == 0).sum()}, Hazardous: {(df['Hazardous'] == 1).sum()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_viz = df.copy()\n",
                "feature_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
                "feature_cols.remove('Hazardous')\n",
                "\n",
                "scaler = StandardScaler()\n",
                "df[feature_cols] = scaler.fit_transform(df[feature_cols])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "hazardous = df_viz[df_viz['Hazardous'] == 1]['Absolute Magnitude']\n",
                "safe = df_viz[df_viz['Hazardous'] == 0]['Absolute Magnitude']\n",
                "\n",
                "ax.hist(safe, bins=50, alpha=0.7, label='Safe', color='#2ecc71', edgecolor='white')\n",
                "ax.hist(hazardous, bins=50, alpha=0.7, label='Hazardous', color='#e74c3c', edgecolor='white')\n",
                "ax.axvline(x=22.0, color='#f39c12', linestyle='--', linewidth=2.5, label='NASA Threshold (H=22.0)')\n",
                "ax.set_xlabel('Absolute Magnitude (H)')\n",
                "ax.set_ylabel('Frequency')\n",
                "ax.set_title('Absolute Magnitude Distribution')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "key_features = ['Absolute Magnitude', 'Est Dia in KM(max)', 'Relative Velocity km per sec',\n",
                "                'Miss Dist.(Astronomical)', 'Minimum Orbit Intersection', 'Eccentricity',\n",
                "                'Semi Major Axis', 'Inclination', 'Orbital Period', 'Hazardous']\n",
                "key_features = [f for f in key_features if f in df_viz.columns]\n",
                "\n",
                "corr_matrix = df_viz[key_features].corr()\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 10))\n",
                "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
                "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', center=0, square=True, ax=ax)\n",
                "ax.set_title('Feature Correlations')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df.drop('Hazardous', axis=1)\n",
                "y = df['Hazardous']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(f\"Imbalance ratio: {(y == 0).sum() / (y == 1).sum():.1f}:1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "smote = SMOTE(random_state=42)\n",
                "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
                "print(f\"SMOTE - Before: {Counter(y_train)}, After: {Counter(y_train_smote)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "undersample = RandomUnderSampler(random_state=42)\n",
                "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
                "print(f\"Undersampling - Before: {Counter(y_train)}, After: {Counter(y_train_under)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_weight_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
                "\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', max_depth=15, random_state=42, n_jobs=-1),\n",
                "    'XGBoost': xgb.XGBClassifier(n_estimators=100, scale_pos_weight=class_weight_ratio, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1),\n",
                "    'LightGBM': lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1, verbose=-1)\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "\n",
                "for name, model in models.items():\n",
                "    start = time.time()\n",
                "    model.fit(X_train, y_train)\n",
                "    train_time = time.time() - start\n",
                "    \n",
                "    y_pred = model.predict(X_test)\n",
                "    y_proba = model.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    results.append({\n",
                "        'Model': name,\n",
                "        'Recall': recall_score(y_test, y_pred),\n",
                "        'Precision': precision_score(y_test, y_pred),\n",
                "        'F1': f1_score(y_test, y_pred),\n",
                "        'AUC-ROC': roc_auc_score(y_test, y_proba),\n",
                "        'Time': train_time,\n",
                "        'Probabilities': y_proba\n",
                "    })\n",
                "    print(f\"{name}: Recall={results[-1]['Recall']:.4f}, AUC={results[-1]['AUC-ROC']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.DataFrame(results).sort_values('Recall', ascending=False)\n",
                "print(results_df[['Model', 'Recall', 'Precision', 'F1', 'AUC-ROC']].to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1 = axes[0]\n",
                "for r in results:\n",
                "    fpr, tpr, _ = roc_curve(y_test, r['Probabilities'])\n",
                "    ax1.plot(fpr, tpr, label=f\"{r['Model']} (AUC={r['AUC-ROC']:.3f})\", linewidth=2)\n",
                "ax1.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
                "ax1.set_xlabel('False Positive Rate')\n",
                "ax1.set_ylabel('True Positive Rate')\n",
                "ax1.set_title('ROC Curves')\n",
                "ax1.legend(loc='lower right')\n",
                "\n",
                "ax2 = axes[1]\n",
                "x = np.arange(len(results_df))\n",
                "width = 0.35\n",
                "ax2.bar(x - width/2, results_df['Recall'], width, label='Recall', color='#e74c3c')\n",
                "ax2.bar(x + width/2, results_df['AUC-ROC'], width, label='AUC-ROC', color='#3498db')\n",
                "ax2.set_xticks(x)\n",
                "ax2.set_xticklabels(results_df['Model'], rotation=15, ha='right')\n",
                "ax2.set_title('Model Comparison')\n",
                "ax2.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_model = models[results_df.iloc[0]['Model']]\n",
                "y_pred_best = best_model.predict(X_test)\n",
                "cm = confusion_matrix(y_test, y_pred_best)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='RdYlGn_r', xticklabels=['Safe', 'Hazardous'], yticklabels=['Safe', 'Hazardous'], ax=ax)\n",
                "ax.set_xlabel('Predicted')\n",
                "ax.set_ylabel('Actual')\n",
                "ax.set_title('Confusion Matrix')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "importance = pd.DataFrame({'Feature': X.columns, 'Importance': models['XGBoost'].feature_importances_}).sort_values('Importance', ascending=False)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "top = importance.head(10)\n",
                "ax.barh(range(len(top)), top['Importance'], color=plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(top))))\n",
                "ax.set_yticks(range(len(top)))\n",
                "ax.set_yticklabels(top['Feature'])\n",
                "ax.invert_yaxis()\n",
                "ax.set_xlabel('Importance')\n",
                "ax.set_title('Top 10 Feature Importance')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df[['Model', 'Recall', 'Precision', 'F1', 'AUC-ROC', 'Time']].to_csv(r'd:\\as\\final_results.csv', index=False)\n",
                "print(\"Results saved.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}